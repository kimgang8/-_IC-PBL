# data_transformed2 검증 손실이 최소가 될 때 모델을 저장(스케쥴러 검증손실을 기준)-배치 크기
import torch
from torch.utils.data import DataLoader, TensorDataset
from torch import nn
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score
from torch.optim.lr_scheduler import ReduceLROnPlateau
import matplotlib.pyplot as plt

# 신경망 모델 정의
class NeuralNet(nn.Module):
    def __init__(self, input_size):
        super(NeuralNet, self).__init__()
        self.fc1 = nn.Linear(input_size, 256)
        self.bn1 = nn.BatchNorm1d(256)
        self.fc2 = nn.Linear(256, 256)
        self.bn2 = nn.BatchNorm1d(256)
        self.dropout = nn.Dropout(0.6)
        self.fc3 = nn.Linear(256, 128)
        self.bn3 = nn.BatchNorm1d(128)
        self.fc4 = nn.Linear(128, 64)
        self.bn4 = nn.BatchNorm1d(64)
        self.fc5 = nn.Linear(64, 32)
        self.bn5 = nn.BatchNorm1d(32)
        self.fc6 = nn.Linear(32, 16)
        self.bn6 = nn.BatchNorm1d(16)
        self.output = nn.Linear(16, 1)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.bn1(self.fc1(x)))
        x = self.dropout(x)
        x = self.relu(self.bn2(self.fc2(x)))
        x = self.dropout(x)
        x = self.relu(self.bn3(self.fc3(x)))
        x = self.dropout(x)
        x = self.relu(self.bn4(self.fc4(x)))
        x = self.dropout(x)
        x = self.relu(self.bn5(self.fc5(x)))
        x = self.dropout(x)
        x = self.relu(self.bn6(self.fc6(x)))
        x = self.dropout(x)
        x = torch.sigmoid(self.output(x))
        return x



# 데이터 로드 및 전처리

combined_data = pd.read_csv('data_transformed3.csv')
train_data = combined_data[combined_data['motor_id'].between(1,36)]
test_data =  combined_data[combined_data['motor_id'].between(37,48)]



X_train = train_data.drop(['class','motor_id','Crest_Factor'], axis=1)
y_train = train_data['class']
X_test = test_data.drop(['class','motor_id','Crest_Factor'], axis=1)
y_test = test_data['class']

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Tensor로 변환
X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32)
X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)
y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)


# 데이터 로더 설정
train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

# 검증 데이터 로더 설정
val_dataset = TensorDataset(X_test_tensor, y_test_tensor)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)

# 모델 초기화 및 설정
input_size = X_train.shape[1]
model = NeuralNet(input_size)
criterion = nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.01)
scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)

# 성능 메트릭 기록을 위한 리스트 (훈련 데이터 추가)
train_metrics_history = {'accuracy': [], 'precision': [], 'recall': [], 'roc_auc': [], 'f1': []}

# 학습 루프
epochs = 1000

# 성능 메트릭 기록을 위한 리스트
train_loss_history = []
val_loss_history = []

test_metrics_history = {'accuracy': [], 'precision': [], 'recall': [], 'roc_auc': [], 'f1': []}

best_val_loss = float('inf')  # 최고 검증 손실 초기화 (무한대로 설정)

patience = 10  # 조기 종료를 위한 인내심 설정
counter = 0  # 성능이 개선되지 않은 에포크 수를 추적

for epoch in range(epochs):
    model.train()
    total_loss = 0
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs.squeeze(), labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    average_loss = total_loss / len(train_loader)
    train_loss_history.append(average_loss)

    # 검증 손실 계산
    model.eval()
    total_val_loss = 0.0
    with torch.no_grad():
        for inputs, labels in val_loader:
            outputs = model(inputs)
            val_loss = criterion(outputs.squeeze(), labels)
            total_val_loss += val_loss.item()
    average_val_loss = total_val_loss / len(val_loader)
    val_loss_history.append(average_val_loss)

    # 훈련 데이터 성능 평가
    with torch.no_grad():
        outputs = model(X_train_tensor)
        predicted = outputs.round().squeeze()
        train_accuracy = accuracy_score(y_train_tensor.numpy(), predicted.numpy())
        train_precision = precision_score(y_train_tensor.numpy(), predicted.numpy())
        train_recall = recall_score(y_train_tensor.numpy(), predicted.numpy())
        train_roc_auc = roc_auc_score(y_train_tensor.numpy(), predicted.numpy())
        train_f1 = f1_score(y_train_tensor.numpy(), predicted.numpy())

        # 훈련 데이터 성능 메트릭 기록
        train_metrics_history['accuracy'].append(train_accuracy)
        train_metrics_history['precision'].append(train_precision)
        train_metrics_history['recall'].append(train_recall)
        train_metrics_history['roc_auc'].append(train_roc_auc)
        train_metrics_history['f1'].append(train_f1)

    # 검증 성능 평가
    with torch.no_grad():
        outputs = model(X_test_tensor)
        predicted = outputs.round().squeeze()
        accuracy = accuracy_score(y_test_tensor.numpy(), predicted.numpy())
        precision = precision_score(y_test_tensor.numpy(), predicted.numpy())
        recall = recall_score(y_test_tensor.numpy(), predicted.numpy())
        roc_auc = roc_auc_score(y_test_tensor.numpy(), predicted.numpy())
        f1 = f1_score(y_test_tensor.numpy(), predicted.numpy())

        # 결과값 출력
        print(f"Epoch {epoch + 1}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, ROC AUC: {roc_auc:.4f}, F1 Score: {f1:.4f}")

        # 성능 메트릭 기록
        test_metrics_history['accuracy'].append(accuracy)
        test_metrics_history['precision'].append(precision)
        test_metrics_history['recall'].append(recall)
        test_metrics_history['roc_auc'].append(roc_auc)
        test_metrics_history['f1'].append(f1)

        # 학습률 스케줄러 업데이트
        scheduler.step(average_val_loss)

        # 모델 저장 및 조기 종료 로직
        if average_val_loss < best_val_loss:
            best_val_loss = average_val_loss
            counter = 0  # 성능 개선 시 카운터 초기화
            torch.save(model.state_dict(), 'best_model.pth')
            print(f"Epoch {epoch+1}: 모델 저장됨, Validation Loss: {average_val_loss:.4f}")
            if best_val_loss <= 0.56 :
                print(f"조기 종료: Epoch {epoch}")
                break  # 조기 종료 조건 충족 시 훈련 중단
        else:
            counter += 1  # 성능이 개선되지 않으면 카운터 증가
            if counter >= patience :
                print(f"조기 종료: Epoch {epoch}")
                break  # 조기 종료 조건 충족 시 훈련 중단


# 최종 테스트 성능 평가
model.eval()
with torch.no_grad():
    outputs = model(X_test_tensor)
    predicted = outputs.round().squeeze()
    accuracy = accuracy_score(y_test_tensor.numpy(), predicted.numpy())
    precision = precision_score(y_test_tensor.numpy(), predicted.numpy())
    recall = recall_score(y_test_tensor.numpy(), predicted.numpy())
    roc_auc = roc_auc_score(y_test_tensor.numpy(), predicted.numpy())
    f1 = f1_score(y_test_tensor.numpy(), predicted.numpy())

# 최종 성능 출력
print(f"테스트 성능 - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, ROC AUC: {roc_auc:.4f}, F1 Score: {f1:.4f}")

plt.figure(figsize=(10, 6))

# 훈련 손실과 검증 손실을 동시에 표현
plt.plot(train_loss_history, label='Train Loss', color='blue')
plt.plot(val_loss_history, label='Validation Loss', color='green')

# 축 레이블과 타이틀 설정
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss over Epochs')

# 범례 표시
plt.legend()

# 그래프 표시
plt.show()